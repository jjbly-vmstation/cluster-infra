---
# Ensures kube-dns ClusterIP is reachable from pods.
# Fixes common node-level causes (ip_forward disabled, FORWARD policy DROP, missing br_netfilter)
# and restarts kube-proxy to re-program Service/NAT rules.

- name: Ensure kube-dns Service exists
  ansible.builtin.command: >-
    kubectl --kubeconfig={{ kubeconfig }} -n kube-system get svc kube-dns
  register: kube_dns_svc
  changed_when: false

- name: Capture kube-dns Service (yaml)
  ansible.builtin.command: >-
    kubectl --kubeconfig={{ kubeconfig }} -n kube-system get svc kube-dns -o yaml
  register: kube_dns_svc_yaml
  changed_when: false
  failed_when: false

- name: Capture kube-dns Endpoints (yaml)
  ansible.builtin.command: >-
    kubectl --kubeconfig={{ kubeconfig }} -n kube-system get endpoints kube-dns -o yaml
  register: kube_dns_ep_yaml
  changed_when: false
  failed_when: false

- name: Capture kube-proxy DaemonSet (yaml)
  ansible.builtin.command: >-
    kubectl --kubeconfig={{ kubeconfig }} -n kube-system get ds kube-proxy -o yaml
  register: kube_proxy_ds_yaml
  changed_when: false
  failed_when: false

- name: Capture kube-proxy pods placement (wide)
  ansible.builtin.command: >-
    kubectl --kubeconfig={{ kubeconfig }} -n kube-system get pods -l k8s-app=kube-proxy -o wide
  register: kube_proxy_pods_wide
  changed_when: false
  failed_when: false

- name: Capture kube-proxy logs (tail)
  ansible.builtin.command: >-
    kubectl --kubeconfig={{ kubeconfig }} -n kube-system logs ds/kube-proxy --tail=200
  register: kube_proxy_logs_tail
  changed_when: false
  failed_when: false

- name: Read kube-dns ClusterIP
  ansible.builtin.command: >-
    kubectl --kubeconfig={{ kubeconfig }} -n kube-system get svc kube-dns -o jsonpath={.spec.clusterIP}
  register: kube_dns_ip
  changed_when: false

- name: Set kube-dns ClusterIP fact
  ansible.builtin.set_fact:
    kube_dns_cluster_ip: "{{ kube_dns_ip.stdout | trim }}"

- name: Assert kube-dns ClusterIP looks valid
  ansible.builtin.assert:
    that:
      - kube_dns_cluster_ip is match('^([0-9]{1,3}\.){3}[0-9]{1,3}$')
    fail_msg: "kube-dns ClusterIP is not a valid IPv4 address: '{{ kube_dns_cluster_ip }}'"

- name: Cluster DNS smoke test from a pod (kube-system) - initial
  ansible.builtin.shell: |
    set -euo pipefail
    ns=kube-system
    name=dns-smoke-{{ ansible_date_time.epoch }}
    ip="{{ kube_dns_cluster_ip }}"

    # Create a short-lived pod that tries to query kube-dns ClusterIP directly.
    kubectl --kubeconfig={{ kubeconfig }} -n "$ns" delete pod "$name" --ignore-not-found >/dev/null 2>&1 || true
    kubectl --kubeconfig={{ kubeconfig }} -n "$ns" run "$name" \
      --image=nicolaka/netshoot \
      --restart=Never \
      --labels=app=dns-smoke \
      --command -- sh -c "dig @${ip} kubernetes.default.svc.cluster.local +time=2 +tries=1 +short >/dev/null"

    # Wait until it completes (Succeeded or Failed)
    for i in $(seq 1 40); do
      phase=$(kubectl --kubeconfig={{ kubeconfig }} -n "$ns" get pod "$name" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")
      if [ "$phase" = "Succeeded" ]; then
        kubectl --kubeconfig={{ kubeconfig }} -n "$ns" delete pod "$name" --ignore-not-found >/dev/null 2>&1 || true
        exit 0
      fi
      if [ "$phase" = "Failed" ]; then
        kubectl --kubeconfig={{ kubeconfig }} -n "$ns" logs "$name" --all-containers --tail=200 || true
        kubectl --kubeconfig={{ kubeconfig }} -n "$ns" describe pod "$name" || true
        kubectl --kubeconfig={{ kubeconfig }} -n "$ns" delete pod "$name" --ignore-not-found >/dev/null 2>&1 || true
        exit 1
      fi
      sleep 1
    done

    kubectl --kubeconfig={{ kubeconfig }} -n "$ns" logs "$name" --all-containers --tail=200 || true
    kubectl --kubeconfig={{ kubeconfig }} -n "$ns" describe pod "$name" || true
    kubectl --kubeconfig={{ kubeconfig }} -n "$ns" delete pod "$name" --ignore-not-found >/dev/null 2>&1 || true
    exit 2
  args:
    executable: /bin/bash
  register: dns_smoke_initial
  changed_when: false
  failed_when: false

- name: Mark whether kube-dns ClusterIP is reachable
  ansible.builtin.set_fact:
    kube_dns_clusterip_ok: "{{ dns_smoke_initial.rc == 0 }}"

- name: Show DNS smoke test result
  ansible.builtin.debug:
    msg: |
      ============================================
      kube-dns ClusterIP smoke test
      ============================================
      kube-dns ClusterIP: {{ kube_dns_cluster_ip }}
      Result: {{ 'OK' if kube_dns_clusterip_ok else 'FAILED' }} (rc={{ dns_smoke_initial.rc }})
      ============================================

- name: Remediate node sysctls/modules/iptables for Kubernetes networking
  when: not kube_dns_clusterip_ok
  block:
    - name: Ensure br_netfilter and overlay modules are loaded (all nodes)
      ansible.builtin.shell: |
        set -e
        modprobe br_netfilter || true
        modprobe overlay || true
      args:
        executable: /bin/bash
      delegate_to: "{{ item }}"
      loop: "{{ groups['all'] | difference(['localhost']) }}"
      changed_when: false
      failed_when: false

    - name: Ensure Kubernetes sysctls are persisted (all nodes)
      ansible.builtin.blockinfile:
        path: /etc/sysctl.d/99-kubernetes.conf
        create: true
        mode: '0644'
        block: |
          net.ipv4.ip_forward = 1
          net.bridge.bridge-nf-call-iptables = 1
          net.bridge.bridge-nf-call-ip6tables = 1
      delegate_to: "{{ item }}"
      loop: "{{ groups['all'] | difference(['localhost']) }}"

    - name: Apply sysctl settings (all nodes)
      ansible.builtin.command: sysctl --system
      delegate_to: "{{ item }}"
      loop: "{{ groups['all'] | difference(['localhost']) }}"
      changed_when: false
      failed_when: false

    - name: Ensure iptables FORWARD policy is ACCEPT (all nodes)
      ansible.builtin.shell: |
        set -e
        if command -v iptables >/dev/null 2>&1; then
          iptables -P FORWARD ACCEPT || true
        fi
        if command -v iptables-nft >/dev/null 2>&1; then
          iptables-nft -P FORWARD ACCEPT || true
        fi
      args:
        executable: /bin/bash
      delegate_to: "{{ item }}"
      loop: "{{ groups['all'] | difference(['localhost']) }}"
      changed_when: false
      failed_when: false

    - name: Detect kube-proxy config (configmap name + mode) (best-effort)
      ansible.builtin.shell: |
        set -euo pipefail
        # Try common kubespray layouts.
        # 1) ConfigMap named kube-proxy with key config.conf
        if kubectl --kubeconfig={{ kubeconfig }} -n kube-system get cm kube-proxy >/dev/null 2>&1; then
          echo "CM_NAME=kube-proxy"
          mode=$(kubectl --kubeconfig={{ kubeconfig }} -n kube-system get cm kube-proxy -o jsonpath='{.data.config\.conf}' 2>/dev/null | grep -E '^\s*mode:\s*' | head -n1 | awk '{print $2}' | tr -d '"\r' || true)
          echo "MODE=${mode:-unknown}"
          exit 0
        fi

        # 2) ConfigMap named kube-proxy-config (common alt)
        if kubectl --kubeconfig={{ kubeconfig }} -n kube-system get cm kube-proxy-config >/dev/null 2>&1; then
          echo "CM_NAME=kube-proxy-config"
          mode=$(kubectl --kubeconfig={{ kubeconfig }} -n kube-system get cm kube-proxy-config -o jsonpath='{.data.config\.conf}' 2>/dev/null | grep -E '^\s*mode:\s*' | head -n1 | awk '{print $2}' | tr -d '"\r' || true)
          echo "MODE=${mode:-unknown}"
          exit 0
        fi

        echo "CM_NAME="
        echo "MODE=unknown"
      args:
        executable: /bin/bash
      register: kube_proxy_cfg_detect
      changed_when: false
      failed_when: false

    - name: Set kube-proxy config facts
      ansible.builtin.set_fact:
        kube_proxy_configmap_name: "{{ (kube_proxy_cfg_detect.stdout_lines | select('match','^CM_NAME=') | list | first | default('CM_NAME=') ).split('=', 1)[1] }}"
        kube_proxy_mode: "{{ (kube_proxy_cfg_detect.stdout_lines | select('match','^MODE=') | list | first | default('MODE=unknown') ).split('=', 1)[1] }}"

    - name: Show kube-proxy config detection
      ansible.builtin.debug:
        msg: |
          kube-proxy configmap: {{ kube_proxy_configmap_name | default('') }}
          kube-proxy mode (from config): {{ kube_proxy_mode | default('unknown') }}

    - name: If kube-proxy is IPVS, ensure required kernel modules and tools exist (all nodes)
      when: kube_proxy_mode | lower == 'ipvs'
      block:
        - name: Load IPVS-related kernel modules (best-effort)
          ansible.builtin.shell: |
            set -e
            for m in ip_vs ip_vs_rr ip_vs_wrr ip_vs_sh nf_conntrack; do
              modprobe "$m" || true
            done
          args:
            executable: /bin/bash
          delegate_to: "{{ item }}"
          loop: "{{ groups['all'] | difference(['localhost']) }}"
          changed_when: false
          failed_when: false

        - name: Install ipvs/ipset tools (best-effort)
          ansible.builtin.package:
            name:
              - ipset
              - ipvsadm
              - conntrack
            state: present
          delegate_to: "{{ item }}"
          loop: "{{ groups['all'] | difference(['localhost']) }}"
          failed_when: false

    - name: Restart kube-proxy DaemonSet (reprogram Service/NAT rules)
      ansible.builtin.command: >-
        kubectl --kubeconfig={{ kubeconfig }} -n kube-system rollout restart ds/kube-proxy
      register: kube_proxy_restart
      changed_when: true
      failed_when: false

    - name: Wait for kube-proxy rollout
      ansible.builtin.command: >-
        kubectl --kubeconfig={{ kubeconfig }} -n kube-system rollout status ds/kube-proxy --timeout=180s
      register: kube_proxy_rollout
      changed_when: false
      failed_when: false

    - name: Restart CoreDNS deployment (best-effort)
      ansible.builtin.command: >-
        kubectl --kubeconfig={{ kubeconfig }} -n kube-system rollout restart deployment/coredns
      register: coredns_restart
      changed_when: true
      failed_when: false

    - name: Wait for CoreDNS rollout (best-effort)
      ansible.builtin.command: >-
        kubectl --kubeconfig={{ kubeconfig }} -n kube-system rollout status deployment/coredns --timeout=180s
      register: coredns_rollout
      changed_when: false
      failed_when: false

    - name: Cluster DNS smoke test from a pod (kube-system) - after kube-proxy restart
      ansible.builtin.shell: |
        set -euo pipefail
        ns=kube-system
        name=dns-smoke-after-kp-{{ ansible_date_time.epoch }}
        ip="{{ kube_dns_cluster_ip }}"

        kubectl --kubeconfig={{ kubeconfig }} -n "$ns" delete pod "$name" --ignore-not-found >/dev/null 2>&1 || true
        kubectl --kubeconfig={{ kubeconfig }} -n "$ns" run "$name" \
          --image=nicolaka/netshoot \
          --restart=Never \
          --labels=app=dns-smoke \
          --command -- sh -c "dig @${ip} kubernetes.default.svc.cluster.local +time=2 +tries=1 +short >/dev/null"

        for i in $(seq 1 60); do
          phase=$(kubectl --kubeconfig={{ kubeconfig }} -n "$ns" get pod "$name" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")
          if [ "$phase" = "Succeeded" ]; then
            kubectl --kubeconfig={{ kubeconfig }} -n "$ns" delete pod "$name" --ignore-not-found >/dev/null 2>&1 || true
            exit 0
          fi
          if [ "$phase" = "Failed" ]; then
            kubectl --kubeconfig={{ kubeconfig }} -n "$ns" logs "$name" --all-containers --tail=200 || true
            kubectl --kubeconfig={{ kubeconfig }} -n "$ns" describe pod "$name" || true
            kubectl --kubeconfig={{ kubeconfig }} -n "$ns" delete pod "$name" --ignore-not-found >/dev/null 2>&1 || true
            exit 1
          fi
          sleep 1
        done

        kubectl --kubeconfig={{ kubeconfig }} -n "$ns" logs "$name" --all-containers --tail=200 || true
        kubectl --kubeconfig={{ kubeconfig }} -n "$ns" describe pod "$name" || true
        kubectl --kubeconfig={{ kubeconfig }} -n "$ns" delete pod "$name" --ignore-not-found >/dev/null 2>&1 || true
        exit 2
      args:
        executable: /bin/bash
      register: dns_smoke_after_kp
      changed_when: false
      failed_when: false

    - name: If still failing, force kube-proxy to iptables mode via configmap (best-effort)
      when:
        - dns_smoke_after_kp.rc != 0
        - kube_proxy_configmap_name is defined
        - kube_proxy_configmap_name | length > 0
      block:
        - name: Render updated kube-proxy config (mode=iptables)
          ansible.builtin.shell: |
            set -euo pipefail
            cm="{{ kube_proxy_configmap_name }}"
            tmpdir=$(mktemp -d)
            conf="$tmpdir/config.conf"
            kubectl --kubeconfig={{ kubeconfig }} -n kube-system get cm "$cm" -o jsonpath='{.data.config\.conf}' > "$conf"
            if grep -Eq '^\s*mode:\s*ipvs\s*$' "$conf"; then
              sed -i 's/^\s*mode:\s*ipvs\s*$/mode: iptables/' "$conf"
            elif grep -Eq '^\s*mode:\s*"ipvs"\s*$' "$conf"; then
              sed -i 's/^\s*mode:\s*"ipvs"\s*$/mode: "iptables"/' "$conf"
            elif grep -Eq '^\s*mode:\s*' "$conf"; then
              # If mode exists but is something else, leave it.
              true
            else
              # Insert under the top-level (best-effort). This keeps YAML valid in most kube-proxy configs.
              printf '\nmode: iptables\n' >> "$conf"
            fi

            # Patch only data["config.conf"] to avoid clobbering other keys.
            payload=$(python3 -c 'import json,sys; print(json.dumps({"data": {"config.conf": open(sys.argv[1]).read()}}))' "$conf")
            kubectl --kubeconfig={{ kubeconfig }} -n kube-system patch cm "$cm" --type merge -p "$payload"
          args:
            executable: /bin/bash
          register: kube_proxy_cfg_patch
          changed_when: true
          failed_when: false

        - name: Restart kube-proxy after config patch
          ansible.builtin.command: >-
            kubectl --kubeconfig={{ kubeconfig }} -n kube-system rollout restart ds/kube-proxy
          changed_when: true
          failed_when: false

        - name: Wait for kube-proxy rollout after config patch
          ansible.builtin.command: >-
            kubectl --kubeconfig={{ kubeconfig }} -n kube-system rollout status ds/kube-proxy --timeout=240s
          changed_when: false
          failed_when: false

        - name: Cluster DNS smoke test from a pod (kube-system) - after forcing iptables mode
          ansible.builtin.shell: |
            set -euo pipefail
            ns=kube-system
            name=dns-smoke-iptables-{{ ansible_date_time.epoch }}
            ip="{{ kube_dns_cluster_ip }}"

            kubectl --kubeconfig={{ kubeconfig }} -n "$ns" delete pod "$name" --ignore-not-found >/dev/null 2>&1 || true
            kubectl --kubeconfig={{ kubeconfig }} -n "$ns" run "$name" \
              --image=nicolaka/netshoot \
              --restart=Never \
              --labels=app=dns-smoke \
              --command -- sh -c "dig @${ip} kubernetes.default.svc.cluster.local +time=2 +tries=1 +short >/dev/null"

            for i in $(seq 1 60); do
              phase=$(kubectl --kubeconfig={{ kubeconfig }} -n "$ns" get pod "$name" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")
              if [ "$phase" = "Succeeded" ]; then
                kubectl --kubeconfig={{ kubeconfig }} -n "$ns" delete pod "$name" --ignore-not-found >/dev/null 2>&1 || true
                exit 0
              fi
              if [ "$phase" = "Failed" ]; then
                kubectl --kubeconfig={{ kubeconfig }} -n "$ns" logs "$name" --all-containers --tail=200 || true
                kubectl --kubeconfig={{ kubeconfig }} -n "$ns" describe pod "$name" || true
                kubectl --kubeconfig={{ kubeconfig }} -n "$ns" delete pod "$name" --ignore-not-found >/dev/null 2>&1 || true
                exit 1
              fi
              sleep 1
            done

            kubectl --kubeconfig={{ kubeconfig }} -n "$ns" logs "$name" --all-containers --tail=200 || true
            kubectl --kubeconfig={{ kubeconfig }} -n "$ns" describe pod "$name" || true
            kubectl --kubeconfig={{ kubeconfig }} -n "$ns" delete pod "$name" --ignore-not-found >/dev/null 2>&1 || true
            exit 2
          args:
            executable: /bin/bash
          register: dns_smoke_after_iptables
          changed_when: false
          failed_when: false

- name: Compute final DNS smoke-test result
  ansible.builtin.set_fact:
    kube_dns_smoke_rc: "{{ dns_smoke_after_iptables.rc | default(dns_smoke_after_kp.rc | default(dns_smoke_initial.rc | default(1))) }}"

- name: Update kube_dns_clusterip_ok based on final smoke-test
  ansible.builtin.set_fact:
    kube_dns_clusterip_ok: "{{ (kube_dns_smoke_rc | int) == 0 }}"

- name: Select a node for NAT/IPVS diagnostics (best-effort)
  ansible.builtin.set_fact:
    kube_dns_diag_node: "{{ (groups['all'] | difference(['localhost']))[0] }}"
  when: (groups['all'] | difference(['localhost']) | length) > 0

- name: Gather node NAT/IPVS summary (best-effort)
  when:
    - not kube_dns_clusterip_ok
    - kube_dns_diag_node is defined
    - kube_dns_diag_node | length > 0
  ansible.builtin.shell: |
    set -e
    echo "=== host ==="
    hostname -f 2>/dev/null || hostname
    echo

    echo "=== sysctl ==="
    sysctl net.ipv4.ip_forward 2>/dev/null || true
    sysctl net.bridge.bridge-nf-call-iptables 2>/dev/null || true
    sysctl net.bridge.bridge-nf-call-ip6tables 2>/dev/null || true
    echo

    echo "=== modules (ipvs/br) ==="
    lsmod | egrep '^(ip_vs|nf_conntrack|br_netfilter|overlay)\b' || true
    echo

    echo "=== ipvsadm (if present) ==="
    if command -v ipvsadm >/dev/null 2>&1; then
      ipvsadm -Ln || true
    else
      echo "ipvsadm not installed"
    fi
    echo

    echo "=== iptables nat (kube chains) ==="
    if command -v iptables >/dev/null 2>&1; then
      iptables -t nat -S 2>/dev/null | egrep -m 30 'KUBE-|kube-dns|10\.233\.' || true
    else
      echo "iptables not present"
    fi
    echo

    echo "=== nft (kube mentions, if present) ==="
    if command -v nft >/dev/null 2>&1; then
      nft list ruleset 2>/dev/null | egrep -m 30 'KUBE-|kube-dns|10\.233\.' || true
    else
      echo "nft not present"
    fi
  args:
    executable: /bin/bash
  delegate_to: "{{ kube_dns_diag_node }}"
  register: kube_dns_node_nat_summary
  changed_when: false
  failed_when: false

- name: Fail if kube-dns ClusterIP is still not reachable after remediation
  when:
    - not kube_dns_clusterip_ok
  ansible.builtin.fail:
    msg: |
      ============================================================
      Cluster DNS is still broken (pod -> kube-dns ClusterIP failed)
      ============================================================
      kube-dns ClusterIP: {{ kube_dns_cluster_ip }}
      Smoke test rc: {{ kube_dns_smoke_rc | default('unknown') }}

      --- kube-dns service (yaml) ---
      {{ kube_dns_svc_yaml.stdout | default('') }}

      --- kube-dns endpoints (yaml) ---
      {{ kube_dns_ep_yaml.stdout | default('') }}

      --- kube-proxy daemonset (yaml) ---
      {{ kube_proxy_ds_yaml.stdout | default('') }}

      --- kube-proxy pods (wide) ---
      {{ kube_proxy_pods_wide.stdout | default('') }}

      --- kube-proxy logs (tail) ---
      {{ kube_proxy_logs_tail.stdout | default('') }}

      --- node NAT/IPVS summary ({{ kube_dns_diag_node | default('n/a') }}) ---
      {{ kube_dns_node_nat_summary.stdout | default('') }}

      Automated remediation attempted:
      - ensured br_netfilter/overlay modules (best-effort)
      - ensured ipvs modules/tools when kube-proxy is in IPVS mode (best-effort)
      - set sysctls (ip_forward + bridge nf-call)
      - set iptables FORWARD policy ACCEPT (best-effort)
      - forced kube-proxy iptables mode (best-effort)
      - restarted kube-proxy and coredns

      Next likely causes (outside this playbookâ€™s control):
      - kube-proxy running in IPVS mode without ipvs kernel modules
      - node firewall/nftables rules overriding kube-proxy
      - Calico dataplane policy/routing issue

      Suggested immediate debug commands:
        kubectl -n kube-system get ds kube-proxy -o wide
        kubectl -n kube-system logs ds/kube-proxy --tail=200
        kubectl -n kube-system get svc kube-dns -o yaml
        kubectl -n kube-system get endpoints kube-dns -o yaml
      ============================================================
